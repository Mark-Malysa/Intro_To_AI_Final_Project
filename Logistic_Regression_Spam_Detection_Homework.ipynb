{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f00b25d",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaaaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Mark Malysa\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00a5d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Logistic Regression Spam Detection Homework\n",
    "\n",
    "In this homework, you will implement a logistic regression classifier from scratch to detect spam messages using the SMS Spam Collection dataset. This dataset contains SMS messages labeled as 'ham' (not spam) or 'spam,' providing a real-world binary classification problem. Logistic regression is a powerful algorithm that models the probability of a binary outcome, making it well-suited for distinguishing spam from legitimate messages. You’ll work through loading the data, preprocessing text, extracting TF-IDF features, implementing the logistic regression model, applying L1 and L2 regularization, and evaluating performance. Each question builds on the previous one, guiding you step-by-step to create a functional spam detector. By the end, you’ll also reflect on key concepts to solidify your understanding.\n",
    "\n",
    "**Dataset:** The SMS Spam Collection dataset is a public corpus available at [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection). It’s provided as a tab-separated file (`SMSSpamCollection`) with two columns: 'label' (ham or spam) and 'message' (the text). Download it and place it in your working directory.\n",
    "\n",
    "**Objectives:**\n",
    "- Understand logistic regression’s mathematical foundation and implementation.\n",
    "- Learn to preprocess text data and extract meaningful features using TF-IDF.\n",
    "- Explore regularization techniques (L1 and L2) to improve model generalization.\n",
    "- Evaluate model performance using standard classification metrics.\n",
    "- Reflect on theoretical aspects to deepen your grasp of the algorithm.\n",
    "\n",
    "This will be our final assignment, so total 4 assginments.\n",
    "Due Data: The assignment is due on April 20th at 11:59 PM. TA Yashshree will be in charge of this assignment, so please direct any questions about the assignment to her."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructions",
   "metadata": {},
   "source": [
    "## Instructions for Completing the Homework\n",
    "\n",
    "Welcome to this logistic regression assignment! You’ll implement each component of the classifier step-by-step, with starter code provided to guide you. Complete the sections marked `# TODO` by replacing them with your solutions. The notebook uses Python with libraries like pandas, NumPy, and scikit-learn (for evaluation only), ensuring you focus on understanding the algorithm rather than external tools.\n",
    "\n",
    "**Tips:**\n",
    "- Run cells sequentially as later questions depend on earlier ones.\n",
    "- Test your code with print statements to verify outputs.\n",
    "- If stuck, revisit the hints or consult resources like lecture notes.\n",
    "- Contact the TA if you need clarification.\n",
    "\n",
    "Before submission, restart the kernel (Kernel → Restart) and run all cells (Cell → Run All) to ensure everything works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "student_info",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Student Information</h3> Please provide information about yourself.<br>\n",
    "<b>Name</b>:<br> \n",
    "<b>NetID</b>:<br>\n",
    "<b>Recitation #</b>:<br>\n",
    "<b>Notes to Grader</b> (optional):<br>\n",
    "<br><br>\n",
    "<b>IMPORTANT</b>\n",
    "Your work will not be graded without your initials below<br>\n",
    "I certify that this lab represents my own work and I have read the RU academic integrity policies at<br>\n",
    "<a href=\"https://www.cs.rutgers.edu/academics/undergraduate/academic-integrity-policy\">https://www.cs.rutgers.edu/academics/undergraduate/academic-integrity-policy </a><br>\n",
    "<b>Initials</b>:      (e.g., RT for Ruixiang Tang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1",
   "metadata": {},
   "source": [
    "## Question 1: Loading and Exploring the Dataset\n",
    "\n",
    "Before building our logistic regression model, we need to load and understand the SMS Spam Collection dataset. This step is crucial because it sets the foundation for all subsequent tasks—knowing the data’s structure and distribution helps us anticipate challenges like class imbalance. Your goal is to load the dataset into a pandas DataFrame, ensure it’s read correctly despite potential encoding issues, and explore its contents.\n",
    "\n",
    "**Tasks:**\n",
    "- Load the dataset from `SMSSpamCollection` into a DataFrame with columns named 'label' and 'message'.\n",
    "- Display the first 5 rows to inspect the data format.\n",
    "- Compute and print the number of ham and spam messages to understand class distribution.\n",
    "\n",
    "**Why It Matters:** Logistic regression relies on labeled data to learn the decision boundary between classes. Exploring the dataset ensures we’re working with clean, usable input and reveals if spam messages are underrepresented, which could affect model performance.\n",
    "\n",
    "**Hint:** Use `pd.read_csv` with `sep='\\t'` since it’s tab-separated, and `encoding='latin1'` if you encounter encoding errors. Use `value_counts()` to get label counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Load the dataset\n",
    "df = ...\n",
    "\n",
    "# TODO: Display the first 5 rows\n",
    "\n",
    "# TODO: Compute the number of ham and spam messages\n",
    "label_counts = ...\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2",
   "metadata": {},
   "source": [
    "## Question 2: Preprocessing - Tokenization and Normalization\n",
    "\n",
    "Text data like SMS messages is unstructured and messy, containing uppercase letters, punctuation, and varying formats. To make it usable for logistic regression, which requires numerical input, we need to preprocess it into a consistent form. In this question, you’ll create a function to clean and tokenize messages, preparing them for feature extraction in the next step.\n",
    "\n",
    "**Tasks:**\n",
    "- Implement `preprocess_text(text)` to:\n",
    "  - Convert text to lowercase.\n",
    "  - Remove punctuation.\n",
    "  - Tokenize into a list of words by splitting on whitespace.\n",
    "- Apply this function to the 'message' column and store the token lists in a new 'tokens' column.\n",
    "- Print the tokens for the first message to verify your function.\n",
    "\n",
    "**Why It Matters:** Logistic regression can’t process raw text directly—it needs numerical features derived from words. Preprocessing ensures consistency (e.g., 'Hello' and 'hello' are treated the same) and removes noise (like punctuation), improving feature quality for modeling.\n",
    "\n",
    "**Hint:** Use `string.punctuation` and `translate` to remove punctuation efficiently. Apply the function with pandas’ `.apply()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # TODO: Implement this function\n",
    "    # 1. Convert to lowercase\n",
    "    text = ...\n",
    "    # 2. Remove punctuation\n",
    "    text = ...\n",
    "    # 3. Tokenize by splitting on whitespace\n",
    "    tokens = ...\n",
    "    return tokens\n",
    "\n",
    "# TODO: Apply the function to the 'message' column\n",
    "df['tokens'] = ...\n",
    "\n",
    "# TODO: Print the tokens for the first message\n",
    "print(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3",
   "metadata": {},
   "source": [
    "## Question 3: Splitting the Data\n",
    "\n",
    "To train and evaluate our logistic regression model effectively, we need to split the dataset into training and test sets. The training set will be used to learn model parameters, while the test set will assess performance on unseen data. Additionally, logistic regression requires numerical labels, so we’ll map 'ham' and 'spam' to 0 and 1.\n",
    "\n",
    "**Tasks:**\n",
    "- Split the DataFrame into 80% training and 20% test sets.\n",
    "- Create a new column 'label_num' mapping 'ham' to 0 and 'spam' to 1 in both sets.\n",
    "- Extract label arrays `y_train` and `y_test` for later use.\n",
    "- Print the sizes of the training and test sets to confirm the split.\n",
    "\n",
    "**Why It Matters:** Splitting ensures we can evaluate how well the model generalizes, a key aspect of machine learning. Numerical labels are necessary because logistic regression uses them in its cost function and gradient calculations.\n",
    "\n",
    "**Hint:** Use `train_test_split` from scikit-learn with `random_state=42` for reproducibility. Use `.map()` to convert labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Split the data\n",
    "train_df, test_df = ...\n",
    "\n",
    "# Map labels to 0 and 1\n",
    "train_df['label_num'] = train_df['label'].map({'ham': 0, 'spam': 1})\n",
    "test_df['label_num'] = test_df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Extract labels\n",
    "y_train = train_df['label_num'].values\n",
    "y_test = test_df['label_num'].values\n",
    "\n",
    "# TODO: Print the sizes of train and test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4",
   "metadata": {},
   "source": [
    "## Question 4: Computing TF-IDF Features\n",
    "\n",
    "Logistic regression requires numerical features, so we’ll transform our tokenized messages into TF-IDF (Term Frequency-Inverse Document Frequency) vectors. TF-IDF weights words based on their frequency in a message (TF) and rarity across all messages (IDF), highlighting terms that are discriminative between spam and ham. We’ll limit the vocabulary to the top 1000 words to keep the feature space manageable.\n",
    "\n",
    "**Tasks:**\n",
    "- Build a vocabulary of the 1000 most frequent words from the training set.\n",
    "- Compute IDF for each word using the formula: \\( \\text{IDF}(w) = \\log\\left(\\frac{N}{1 + \\text{DF}(w)}\\right) \\), where \\( N \\) is the number of training messages and \\( \\text{DF}(w) \\) is the document frequency.\n",
    "- Implement a function to compute TF-IDF vectors for a message.\n",
    "- Create feature matrices `X_train` and `X_test` and print their shapes.\n",
    "\n",
    "**Why It Matters:** TF-IDF captures word importance better than raw counts, improving the model’s ability to distinguish classes. Limiting the vocabulary reduces computational complexity while retaining key features.\n",
    "\n",
    "**Hint:** Use `Counter` to find frequent words, compute IDF with a smoothing term (1+DF) to avoid division by zero, and use NumPy for efficient matrix operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q4_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Build vocabulary from training set\n",
    "# TODO: Create a list of all words in training set\n",
    "all_words = ...\n",
    "\n",
    "# TODO: Count frequencies and select top 1000 words\n",
    "word_counts = ...\n",
    "vocab = ...\n",
    "\n",
    "# Create a word to index mapping\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# Step 2: Compute IDF\n",
    "df_counts = {word: 0 for word in vocab}\n",
    "for tokens in train_df['tokens']:\n",
    "    unique_words = set(tokens)\n",
    "    for word in unique_words:\n",
    "        if word in df_counts:\n",
    "            df_counts[word] += 1\n",
    "\n",
    "N = len(train_df)\n",
    "idf = {word: np.log(N / (1 + df_counts[word])) for word in vocab}\n",
    "\n",
    "# Step 3: Compute TF-IDF function\n",
    "def compute_tfidf(tokens, vocab, word_to_idx, idf):\n",
    "    tfidf_vector = np.zeros(len(vocab))\n",
    "    word_count = Counter(tokens)\n",
    "    for word, count in word_count.items():\n",
    "        if word in vocab:\n",
    "            idx = word_to_idx[word]\n",
    "            tf = count / len(tokens)  # term frequency\n",
    "            tfidf_vector[idx] = tf * idf[word]\n",
    "    return tfidf_vector\n",
    "\n",
    "# TODO: Create X_train\n",
    "X_train = ...\n",
    "\n",
    "# TODO: Create X_test\n",
    "X_test = ...\n",
    "\n",
    "# Print shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5",
   "metadata": {},
   "source": [
    "## Question 5: Implementing Logistic Regression Functions\n",
    "\n",
    "Now we’ll define the core functions of logistic regression: the sigmoid function to model probabilities, the cost function to measure error, and gradient descent to optimize weights. These components form the backbone of the algorithm, allowing it to learn the relationship between TF-IDF features and spam labels.\n",
    "\n",
    "**Tasks:**\n",
    "- Add a bias term (column of ones) to `X_train` and `X_test`.\n",
    "- Implement `sigmoid(z)`: \\( \\sigma(z) = \\frac{1}{1 + e^{-z}} \\).\n",
    "- Implement `compute_cost(X, y, w)` using binary cross-entropy: \\( J(w) = -\\frac{1}{m} \\sum [y_i \\log(h(x_i)) + (1-y_i) \\log(1-h(x_i))] \\).\n",
    "- Implement `gradient_descent(X, y, w, learning_rate, num_iterations)` to update weights and track cost.\n",
    "\n",
    "**Why It Matters:** The sigmoid function maps predictions to probabilities between 0 and 1, crucial for binary classification. The cost function quantifies prediction errors, and gradient descent iteratively minimizes this error, tuning the model to the data.\n",
    "\n",
    "**Hint:** Use `np.hstack` for the bias term, NumPy’s vectorized operations for efficiency, and include cost tracking every 100 iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q5_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias term\n",
    "X_train_bias = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_test_bias = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "\n",
    "# TODO: Implement sigmoid function\n",
    "def sigmoid(z):\n",
    "    ...\n",
    "\n",
    "# TODO: Implement cost function\n",
    "def compute_cost(X, y, w):\n",
    "    ...\n",
    "\n",
    "# TODO: Implement gradient descent\n",
    "def gradient_descent(X, y, w, learning_rate, num_iterations):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(X @ w)\n",
    "        gradient = ...\n",
    "        w = ...\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost(X, y, w)\n",
    "            costs.append(cost)\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "    return w, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6",
   "metadata": {},
   "source": [
    "## Question 6: Training the Model without Regularization\n",
    "\n",
    "With the logistic regression functions ready, it’s time to train the model on the training data. Training involves initializing weights and using gradient descent to find the optimal values that minimize the cost function. Monitoring the cost over iterations helps verify that the model is learning.\n",
    "\n",
    "**Tasks:**\n",
    "- Initialize weights to zeros for all features plus the bias.\n",
    "- Set hyperparameters: learning rate (e.g., 0.01) and number of iterations (e.g., 1000).\n",
    "- Run gradient descent to train the model and store the trained weights.\n",
    "- Plot the cost over iterations to check convergence.\n",
    "\n",
    "**Why It Matters:** Training is where the model learns to separate spam from ham based on TF-IDF features. A decreasing cost indicates successful optimization, setting the stage for accurate predictions.\n",
    "\n",
    "**Hint:** Use `np.zeros` for initialization, adjust learning rate if cost doesn’t decrease, and use matplotlib for plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q6_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize w to zeros\n",
    "w = ...\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "# TODO: Run gradient descent\n",
    "w_trained, costs = gradient_descent(X_train_bias, y_train, w, learning_rate, num_iterations)\n",
    "\n",
    "# Plot the cost\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0, num_iterations, 100), costs)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost vs. Iterations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7",
   "metadata": {},
   "source": [
    "## Question 7: Making Predictions and Evaluating the Model\n",
    "\n",
    "After training, we’ll use the model to predict whether test messages are spam or ham and evaluate its performance. This step tests how well the model generalizes to new data, a critical measure of its practical utility as a spam filter.\n",
    "\n",
    "**Tasks:**\n",
    "- Implement `predict(X, w)` to compute probabilities and classify (1 if probability >= 0.5, else 0).\n",
    "- Make predictions on the test set.\n",
    "- Compute and print accuracy, precision, recall, and F1-score for the spam class.\n",
    "\n",
    "**Why It Matters:** Predictions show the model in action, while evaluation metrics reveal its strengths (e.g., high precision means fewer false positives) and weaknesses (e.g., low recall means missed spam). These insights guide improvements.\n",
    "\n",
    "**Hint:** Use the sigmoid function in predictions, leverage scikit-learn metrics for simplicity, and focus on the spam class (positive label).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q7_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement predict function\n",
    "def predict(X, w):\n",
    "    probabilities = ...\n",
    "\n",
    "# TODO: Make predictions on test set\n",
    "y_pred = ...\n",
    "\n",
    "# TODO: Compute evaluation metrics\n",
    "\n",
    "accuracy = ...\n",
    "precision = ...\n",
    "recall = ...\n",
    "f1 = ...\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q8",
   "metadata": {},
   "source": [
    "## Question 8: Implementing L2 Regularization\n",
    "\n",
    "Regularization helps prevent overfitting by penalizing large weights, improving generalization. L2 regularization adds a penalty proportional to the squared magnitude of weights, encouraging smaller, more balanced values. Here, you’ll modify the model to include L2 regularization and assess its impact.\n",
    "\n",
    "**Tasks:**\n",
    "- Implement `compute_cost_L2(X, y, w, lambda_)` with the L2 term: \\( \\frac{\\lambda}{2m} \\sum w_j^2 \\) (exclude bias).\n",
    "- Implement `gradient_descent_L2` with the adjusted gradient: \\( \\frac{\\partial J}{\\partial w_j} + \\frac{\\lambda}{m} w_j \\) (exclude bias).\n",
    "- Train with multiple lambda values (e.g., 0.1, 1, 10, 100), plot cost, and evaluate accuracy and weight magnitude.\n",
    "- Observe how changing lambda affects the model.\n",
    "\n",
    "**Why It Matters:** L2 regularization reduces model complexity, which can improve performance on test data, especially if the unregularized model overfits the training set.\n",
    "\n",
    "**Hint:** Apply the penalty only to feature weights (not bias), test a wide range of lambda values (0.1 to 100), and inspect weight norms to see the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q8_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify compute_cost for L2\n",
    "def compute_cost_L2(X, y, w, lambda_):\n",
    "    ...\n",
    "\n",
    "\n",
    "# TODO: Modify gradient_descent for L2\n",
    "def gradient_descent_L2(X, y, w, learning_rate, num_iterations, lambda_):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    # L2 penalty for weights, not bias\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(X @ w)\n",
    "        gradient = ...\n",
    "        w = ...\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost_L2(X, y, w, lambda_)\n",
    "            costs.append(cost)\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "    return w, costs\n",
    "\n",
    "# Test multiple lambda values\n",
    "lambda_values = [0.1, 1.0, 10.0, 100.0]\n",
    "learning_rate = 0.1  # Increased to make regularization effect more visible\n",
    "num_iterations = 1000\n",
    "\n",
    "for lambda_ in lambda_values:\n",
    "    # Initialize w\n",
    "    w = np.zeros(X_train_bias.shape[1])\n",
    "    \n",
    "    # Train with L2\n",
    "    print(f\"\\nTraining with lambda = {lambda_}\")\n",
    "    w_trained_L2, costs_L2 = gradient_descent_L2(X_train_bias, y_train, w, learning_rate, num_iterations, lambda_)\n",
    "    \n",
    "    # Plot cost\n",
    "    plt.plot(range(0, num_iterations, 100), costs_L2, label=f'lambda={lambda_}')\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred_L2 = predict(X_test_bias, w_trained_L2)\n",
    "    accuracy_L2 = accuracy_score(y_test, y_pred_L2)\n",
    "    weight_norm = np.linalg.norm(w_trained_L2[:-1])  # Exclude bias\n",
    "    print(f\"Accuracy with L2 (lambda={lambda_}): {accuracy_L2:.4f}\")\n",
    "    print(f\"L2 Norm of weights: {weight_norm:.4f}\")\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost vs. Iterations with L2 Regularization')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Comment on how changing lambda affects accuracy and weight magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q9",
   "metadata": {},
   "source": [
    "## Question 9: Implementing L1 Regularization\n",
    "\n",
    "L1 regularization penalizes the absolute value of weights, promoting sparsity by driving some weights to zero. This can simplify the model by selecting only the most important features, which is useful for interpretability in spam detection. You’ll adapt the model for L1 and compare its effects.\n",
    "\n",
    "**Tasks:**\n",
    "- Implement `compute_cost_L1(X, y, w, lambda_)` with the L1 term: \\( \\frac{\\lambda}{m} \\sum |w_j| \\) (exclude bias).\n",
    "- Implement `gradient_descent_L1` with the gradient adjustment: \\( \\frac{\\partial J}{\\partial w_j} + \\frac{\\lambda}{m} \\text{sign}(w_j) \\) (exclude bias).\n",
    "- Train with multiple lambda values (e.g., 0.1, 1, 10, 100), plot cost, and evaluate accuracy and sparsity.\n",
    "- Observe how changing lambda affects the model.\n",
    "\n",
    "**Why It Matters:** L1 regularization can identify key words driving spam classification, potentially improving efficiency and interpretability compared to L2’s smoother penalty.\n",
    "\n",
    "**Hint:** Use `np.sign` for the gradient term, exclude bias from regularization, test a wide range of lambda values (0.1 to 100), and count zero weights to measure sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q9_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify compute_cost for L1\n",
    "def compute_cost_L1(X, y, w, lambda_):\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "# TODO: Modify gradient_descent for L1\n",
    "def gradient_descent_L1(X, y, w, learning_rate, num_iterations, lambda_):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    # L1 penalty for weights, not bias\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(X @ w)\n",
    "        gradient = ...\n",
    "        w = ...\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost_L1(X, y, w, lambda_)\n",
    "            costs.append(cost)\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "    return w, costs\n",
    "\n",
    "# Test multiple lambda values\n",
    "lambda_values = [0.1, 1.0, 10.0, 100.0]\n",
    "learning_rate = 0.1  # Increased to make regularization effect more visible\n",
    "num_iterations = 1000\n",
    "\n",
    "for lambda_ in lambda_values:\n",
    "    # Initialize w\n",
    "    w = np.zeros(X_train_bias.shape[1])\n",
    "    \n",
    "    # Train with L1\n",
    "    print(f\"\\nTraining with lambda = {lambda_}\")\n",
    "    w_trained_L1, costs_L1 = gradient_descent_L1(X_train_bias, y_train, w, learning_rate, num_iterations, lambda_)\n",
    "    \n",
    "    # Plot cost\n",
    "    plt.plot(range(0, num_iterations, 100), costs_L1, label=f'lambda={lambda_}')\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred_L1 = predict(X_test_bias, w_trained_L1)\n",
    "    accuracy_L1 = accuracy_score(y_test, y_pred_L1)\n",
    "    num_zeros = np.sum(np.abs(w_trained_L1[:-1]) < 1e-5)  # Count near-zero weights\n",
    "    print(f\"Accuracy with L1 (lambda={lambda_}): {accuracy_L1:.4f}\")\n",
    "    print(f\"Number of near-zero weights: {num_zeros} out of {len(w_trained_L1[:-1])}\")\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost vs. Iterations with L1 Regularization')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Comment on how changing lambda affects accuracy and sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q10",
   "metadata": {},
   "source": [
    "## Question 10: Theoretical Questions\n",
    "\n",
    "To wrap up, let’s reflect on the concepts behind logistic regression and regularization. These questions test your understanding of how the algorithm works and why we use techniques like L1 and L2 regularization, connecting theory to your practical implementation.\n",
    "\n",
    "**Tasks:** Answer the following in the markdown cell below:\n",
    "- **a)** Explain how logistic regression models the probability of a binary outcome and the role of the sigmoid function.\n",
    "- **b)** Based on your results from Questions 8 and 9, discuss the differences between L1 and L2 regularization in terms of their effects on model weights (e.g., magnitude, sparsity) and performance (e.g., accuracy). Explain when you might prefer one over the other, considering your observations with different lambda values.\n",
    "\n",
    "**Why It Matters:** Understanding the theory ensures you can apply logistic regression effectively beyond this homework, adapting it to new problems and interpreting results critically.\n",
    "\n",
    "**Hint:** For a), focus on the linear combination and sigmoid’s role in probability mapping. For b), use your results (e.g., weight norms, number of zeros, accuracy) to compare L1’s sparsity vs. L2’s shrinkage, and consider scenarios like feature selection vs. stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q10_answers",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "\n",
    "a) [Your answer here]\n",
    "\n",
    "b) [Your answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
